# Generated by Ansible at {{ ansible_date_time.iso8601 }}

# For more information on configuration, see:
#   * Official English Documentation: http://nginx.org/en/docs/
#   * Official Russian Documentation: http://nginx.org/ru/docs/

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log;
pid /run/nginx.pid;
worker_rlimit_nofile 2048;

events {
    worker_connections 1024;
    multi_accept on;
    use epoll;
}

http {
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log off;


    ##
    # Basic Settings
    ##

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 40;
    client_header_timeout 60;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 8k;
    send_timeout 60;
    reset_timedout_connection on;
    types_hash_max_size 2048;
    server_tokens off;


    include             /etc/nginx/mime.types;
    default_type        application/octet-stream;

    ##
    # Gzip Settings
    ##
    gzip on;

    # Enable compression both for HTTP/1.0 and HTTP/1.1 (required for CloudFront).
    gzip_http_version  1.0;

    # Compression level (1-9).
    # 5 is a perfect compromise between size and cpu usage, offering about
    # 75% reduction for most ascii files (almost identical to level 9).
    gzip_comp_level    5;

    # Don't compress anything that's already small and unlikely to shrink much
    # if at all (the default is 20 bytes, which is bad as that usually leads to
    # larger files after gzipping).
    gzip_min_length    256;

    # Compress data even for clients that are connecting to us via proxies,
    # identified by the "Via" header (required for CloudFront).
    gzip_proxied       any;

    # Tell proxies to cache both the gzipped and regular version of a resource
    # whenever the client's Accept-Encoding capabilities header varies;
    # Avoids the issue where a non-gzip capable client (which is extremely rare
    # today) would display gibberish if their proxy gave them the gzipped version.
    gzip_vary          on;

    # Compress all output labeled with one of the following MIME-types.
    gzip_types
        application/atom+xml
        application/javascript
        application/json
        application/rss+xml
        application/vnd.ms-fontobject
        application/x-font-ttf
        application/x-web-app-manifest+json
        application/xhtml+xml
        application/xml
        font/opentype
        image/svg+xml
        image/x-icon
        text/css
        text/plain
        text/x-component;

        # Idea being here that we don't need to cache many file descriptors, but we should cache them for a while
        open_file_cache          max=50 inactive=1h;
        open_file_cache_valid    60s;
        open_file_cache_min_uses 1;
        open_file_cache_errors   off;


    server {
        listen 8080 default_server;
        server_name minotar.net;
        root /srv/www/minotar.net/public_html;

        access_log  /srv/www/minotar.net/logs/access.log;
        error_log /srv/www/minotar.net/logs/error.log;

        add_header 'Access-Control-Allow-Origin' '*';

        index index.html;

    }

    # Ideally will deal with this in Varnish
    server {
        listen 8080;
        server_name www.minotar.net;

        rewrite ^ http://minotar.net$request_uri? permanent;
    }

    # Will require a reduced cache ttl
    server {
        listen 8080;
        server_name $hostname;

        location /status {
            stub_status on;
            access_log   off;
        }
    }
}
